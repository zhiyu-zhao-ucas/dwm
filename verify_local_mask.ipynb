{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证 Inference 模型预测的 Local Mask\n",
    "\n",
    "本notebook用于加载保存的inference模型，创建环境，并验证模型预测的local mask是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 设置显示格式\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "# 确保当前目录在path中\n",
    "if not os.getcwd() in sys.path:\n",
    "    sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的模块\n",
    "from fcdl.env.chemical_env import Chemical\n",
    "from fcdl.model.encoder import make_encoder\n",
    "from fcdl.model.inference_ours_masking import InferenceOursMask\n",
    "from fcdl.model.inference_dwm import InferenceDWM\n",
    "from fcdl.model.inference_ncd import InferenceNCD\n",
    "from fcdl.utils.utils import TrainingParams, get_env, update_obs_act_spec\n",
    "from fcdl.utils.replay_buffer import ReplayBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载保存的参数和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型路径\n",
    "name = \"ncd-1\"\n",
    "model_path = f\"data1/iwhwang/causal_rl/Chemical/{name}/trained_models/inference_15k\"\n",
    "params_path = f\"data1/iwhwang/causal_rl/Chemical/{name}/params\"\n",
    "env_params_path = f\"data1/iwhwang/causal_rl/Chemical/{name}/params\"\n",
    "\n",
    "# 检查文件是否存在\n",
    "assert os.path.exists(model_path), f\"模型文件不存在: {model_path}\"\n",
    "assert os.path.exists(params_path), f\"参数文件不存在: {params_path}\"\n",
    "assert os.path.exists(env_params_path), f\"环境参数文件不存在: {env_params_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载参数和环境设置\n"
     ]
    }
   ],
   "source": [
    "# 加载参数\n",
    "params_dict = torch.load(params_path)\n",
    "params = TrainingParams(training_params_fname=\"policy_params.json\", train=False)\n",
    "\n",
    "# 将加载的参数字典复制到params对象\n",
    "for key, value in params_dict.items():\n",
    "    setattr(params, key, value)\n",
    "\n",
    "# 加载环境参数\n",
    "env_params = torch.load(env_params_path)\n",
    "print(f\"已加载参数和环境设置\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_params = TrainingParams(training_params_fname=\"policy_params.json\", train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('seed', 'Different values', 'params: 1', 'classical: -1')\n",
      "('ours_params', 'Different values', \"params: {'feature_fc_dims': [128, 128], 'generative_fc_dims': [128, 128], 'vq_encode_fc_dims': [128, 64], 'vq_decode_fc_dims': [32], 'ncd_fc_dims': [128, 128], 'code_labeling': True, 'vqvae_ema': True, 'ema': 0.99, 'codebook_size': 16, 'code_dim': 16, 'reg_coef': 0.001, 'vq_coef': 1.0, 'commit_coef': 0.25, 'local_mask_sampling_num': 1, 'eval_local_mask_sampling_num': 1}\", \"classical: {'feature_fc_dims': [128, 128], 'generative_fc_dims': [128, 128], 'vq_encode_fc_dims': [128, 64], 'vq_decode_fc_dims': [32], 'ncd_fc_dims': [128, 128], 'code_labeling': False, 'vqvae_ema': True, 'ema': 0.99, 'codebook_size': 16, 'code_dim': 16, 'reg_coef': 0.001, 'vq_coef': 1.0, 'commit_coef': 0.25, 'local_mask_sampling_num': 1, 'eval_local_mask_sampling_num': 1}\")\n",
      "('training_params', 'Different values', \"params: {'inference_algo': 'ncd', 'rl_algo': 'model_based', 'load_id': None, 'load_inference': None, 'load_model_based': None, 'load_policy': None, 'load_replay_buffer': None, 'total_steps': 16100, 'init_steps': 1000, 'random_action_steps': 1000, 'inference_gradient_steps': 1, 'inference_update_freq': 1, 'policy_update_freq': 1, 'test_freq': 500, 'ood_eval_freq': 500, 'ood_eval_batch_size': 1024, 'total_test_episode_num': 10, 'saving_freq': 5000, 'plot_freq': 1000, 'mute_wandb': False, 'replay_buffer_params': {'capacity': 1000000, 'max_sample_time': 128, 'saving_freq': 0}}\", \"classical: {'inference_algo': 'ours', 'rl_algo': 'model_based', 'load_id': None, 'load_inference': None, 'load_model_based': None, 'load_policy': None, 'load_replay_buffer': None, 'total_steps': 16100, 'init_steps': 1000, 'random_action_steps': 1000, 'inference_gradient_steps': 1, 'inference_update_freq': 1, 'policy_update_freq': 1, 'test_freq': 500, 'ood_eval_freq': 500, 'ood_eval_batch_size': 1024, 'total_test_episode_num': 10, 'saving_freq': 5000, 'plot_freq': 1000, 'zero_shot': False, 'zero_shot_total_test_episode_num': 64, 'mute_wandb': False, 'replay_buffer_params': {'capacity': 1000000, 'max_sample_time': 128, 'saving_freq': 0}}\")\n",
      "('replay_buffer_dir', 'Only in params', 'None')\n",
      "('device', 'Only in params', 'cuda')\n",
      "('mute_wandb', 'Only in params', 'False')\n",
      "('rslts_dir', 'Only in params', './data1/iwhwang/causal_rl/Chemical/3mb1v1ve/')\n",
      "('continuous_state', 'Only in params', 'False')\n",
      "('continuous_action', 'Only in params', 'False')\n",
      "('continuous_factor', 'Only in params', 'False')\n",
      "('action_dim', 'Only in params', '50')\n",
      "('feature_inner_dim', 'Only in params', '[5 5 5 5 5 5 5 5 5 5]')\n",
      "('obs_spec', 'Only in params', \"{'obj0': array([0.], dtype=float32), 'obj1': array([4.], dtype=float32), 'obj2': array([2.], dtype=float32), 'obj3': array([2.], dtype=float32), 'obj4': array([1.], dtype=float32), 'obj5': array([4.], dtype=float32), 'obj6': array([4.], dtype=float32), 'obj7': array([2.], dtype=float32), 'obj8': array([4.], dtype=float32), 'obj9': array([1.], dtype=float32), 'target_obj0': array([0.], dtype=float32), 'target_obj1': array([2.], dtype=float32), 'target_obj2': array([3.], dtype=float32), 'target_obj3': array([2.], dtype=float32), 'target_obj4': array([2.], dtype=float32), 'target_obj5': array([2.], dtype=float32), 'target_obj6': array([3.], dtype=float32), 'target_obj7': array([0.], dtype=float32), 'target_obj8': array([4.], dtype=float32), 'target_obj9': array([2.], dtype=float32)}\")\n",
      "('num_action_variable', 'Only in params', '1')\n",
      "('obs_dims', 'Only in params', \"{'obj0': array([5]), 'obj1': array([5]), 'obj2': array([5]), 'obj3': array([5]), 'obj4': array([5]), 'obj5': array([5]), 'obj6': array([5]), 'obj7': array([5]), 'obj8': array([5]), 'obj9': array([5]), 'target_obj0': array([5]), 'target_obj1': array([5]), 'target_obj2': array([5]), 'target_obj3': array([5]), 'target_obj4': array([5]), 'target_obj5': array([5]), 'target_obj6': array([5]), 'target_obj7': array([5]), 'target_obj8': array([5]), 'target_obj9': array([5])}\")\n",
      "('action_spec', 'Only in params', 'None')\n"
     ]
    }
   ],
   "source": [
    "# Find the difference between classical_params and params\n",
    "def get_param_dict(obj):\n",
    "    return {k: v for k, v in obj.__dict__.items() if not k.startswith('_')}\n",
    "\n",
    "classical_dict = get_param_dict(classical_params)\n",
    "params_dict = get_param_dict(params)\n",
    "\n",
    "# Create a function to safely compare objects\n",
    "def compare_values(v1, v2):\n",
    "    \"\"\"Compare values, handling unhashable types\"\"\"\n",
    "    try:\n",
    "        return v1 == v2\n",
    "    except:\n",
    "        return str(v1) == str(v2)\n",
    "\n",
    "# Store differences in a list (not a set)\n",
    "differences = []\n",
    "\n",
    "# Find keys that are in params but not in classical_params or have different values\n",
    "for key, value in params_dict.items():\n",
    "    if key not in classical_dict:\n",
    "        differences.append((key, \"Only in params\", str(value)))\n",
    "    elif not compare_values(classical_dict[key], value):\n",
    "        differences.append((key, \"Different values\", \n",
    "                          f\"params: {str(value)}\", \n",
    "                          f\"classical: {str(classical_dict[key])}\"))\n",
    "\n",
    "# Find keys that are in classical_params but not in params\n",
    "for key, value in classical_dict.items():\n",
    "    if key not in params_dict:\n",
    "        differences.append((key, \"Only in classical_params\", str(value)))\n",
    "\n",
    "# Display the differences\n",
    "for diff in differences:\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('action_dim', 50),\n",
       " ('action_spec', None),\n",
       " ('continuous_action', False),\n",
       " ('continuous_factor', False),\n",
       " ('continuous_state', False),\n",
       " ('device', device(type='cuda')),\n",
       " ('feature_inner_dim', (5, 5, 5, 5, 5, 5, 5, 5, 5, 5)),\n",
       " ('mute_wandb', False),\n",
       " ('num_action_variable', 1),\n",
       " ('obs_dims',\n",
       "  frozenset({('obj0', (5,)),\n",
       "             ('obj1', (5,)),\n",
       "             ('obj2', (5,)),\n",
       "             ('obj3', (5,)),\n",
       "             ('obj4', (5,)),\n",
       "             ('obj5', (5,)),\n",
       "             ('obj6', (5,)),\n",
       "             ('obj7', (5,)),\n",
       "             ('obj8', (5,)),\n",
       "             ('obj9', (5,)),\n",
       "             ('target_obj0', (5,)),\n",
       "             ('target_obj1', (5,)),\n",
       "             ('target_obj2', (5,)),\n",
       "             ('target_obj3', (5,)),\n",
       "             ('target_obj4', (5,)),\n",
       "             ('target_obj5', (5,)),\n",
       "             ('target_obj6', (5,)),\n",
       "             ('target_obj7', (5,)),\n",
       "             ('target_obj8', (5,)),\n",
       "             ('target_obj9', (5,))})),\n",
       " ('obs_spec',\n",
       "  frozenset({('obj0', (0.0,)),\n",
       "             ('obj1', (4.0,)),\n",
       "             ('obj2', (2.0,)),\n",
       "             ('obj3', (2.0,)),\n",
       "             ('obj4', (1.0,)),\n",
       "             ('obj5', (4.0,)),\n",
       "             ('obj6', (4.0,)),\n",
       "             ('obj7', (2.0,)),\n",
       "             ('obj8', (4.0,)),\n",
       "             ('obj9', (1.0,)),\n",
       "             ('target_obj0', (0.0,)),\n",
       "             ('target_obj1', (2.0,)),\n",
       "             ('target_obj2', (3.0,)),\n",
       "             ('target_obj3', (2.0,)),\n",
       "             ('target_obj4', (2.0,)),\n",
       "             ('target_obj5', (2.0,)),\n",
       "             ('target_obj6', (3.0,)),\n",
       "             ('target_obj7', (0.0,)),\n",
       "             ('target_obj8', (4.0,)),\n",
       "             ('target_obj9', (2.0,))})),\n",
       " ('ours_params',\n",
       "  frozenset({('code_dim', 16),\n",
       "             ('code_labeling', True),\n",
       "             ('codebook_size', 16),\n",
       "             ('commit_coef', 0.25),\n",
       "             ('ema', 0.99),\n",
       "             ('eval_local_mask_sampling_num', 1),\n",
       "             ('feature_fc_dims', (128, 128)),\n",
       "             ('generative_fc_dims', (128, 128)),\n",
       "             ('local_mask_sampling_num', 1),\n",
       "             ('ncd_fc_dims', (128, 128)),\n",
       "             ('reg_coef', 0.001),\n",
       "             ('vq_coef', 1.0),\n",
       "             ('vq_decode_fc_dims', (32,)),\n",
       "             ('vq_encode_fc_dims', (128, 64)),\n",
       "             ('vqvae_ema', True)})),\n",
       " ('replay_buffer_dir', None),\n",
       " ('rslts_dir', './data1/iwhwang/causal_rl/Chemical/3mb1v1ve/'),\n",
       " ('seed', 1),\n",
       " ('training_params',\n",
       "  frozenset({('inference_algo', 'ncd'),\n",
       "             ('inference_gradient_steps', 1),\n",
       "             ('inference_update_freq', 1),\n",
       "             ('init_steps', 1000),\n",
       "             ('load_id', None),\n",
       "             ('load_inference', None),\n",
       "             ('load_model_based', None),\n",
       "             ('load_policy', None),\n",
       "             ('load_replay_buffer', None),\n",
       "             ('mute_wandb', False),\n",
       "             ('ood_eval_batch_size', 1024),\n",
       "             ('ood_eval_freq', 500),\n",
       "             ('plot_freq', 1000),\n",
       "             ('policy_update_freq', 1),\n",
       "             ('random_action_steps', 1000),\n",
       "             ('replay_buffer_params',\n",
       "              frozenset({('capacity', 1000000),\n",
       "                         ('max_sample_time', 128),\n",
       "                         ('saving_freq', 0)})),\n",
       "             ('rl_algo', 'model_based'),\n",
       "             ('saving_freq', 5000),\n",
       "             ('test_freq', 500),\n",
       "             ('total_steps', 16100),\n",
       "             ('total_test_episode_num', 10)}))}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "params.device = device\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 创建环境和推理模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境创建完成: Chemical\n"
     ]
    }
   ],
   "source": [
    "# 创建环境\n",
    "# 强制使用单个环境，不使用向量化环境\n",
    "params.env_params.num_env = 1  # 确保只使用一个环境\n",
    "env = get_env(params)\n",
    "print(f\"环境创建完成: {params.env_params.env_name}\")\n",
    "\n",
    "# 更新观测和动作空间\n",
    "update_obs_act_spec(env, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-16 09:04:59.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfcdl.model.inference_ours_masking\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mInferenceOursMask\u001b[0m\n",
      "\u001b[32m2025-03-16 09:04:59.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfcdl.model.inference_ours_base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mInferenceOursBase\u001b[0m\n",
      "\u001b[32m2025-03-16 09:04:59.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfcdl.model.inference_ours_base\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mset up local causal model\u001b[0m\n",
      "\u001b[32m2025-03-16 09:04:59.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfcdl.model.gumbel\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mSet up EMB\u001b[0m\n",
      "\u001b[32m2025-03-16 09:04:59.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfcdl.model.gumbel\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mSet up EMB\u001b[0m\n",
      "\u001b[32m2025-03-16 09:05:00.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfcdl.model.inference_ours_base\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m310\u001b[0m - \u001b[1mloading inference model from data1/iwhwang/causal_rl/Chemical/ncd-1/trained_models/inference_15k\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference loaded data1/iwhwang/causal_rl/Chemical/ncd-1/trained_models/inference_15k\n",
      "推理模型加载完成\n"
     ]
    }
   ],
   "source": [
    "# 创建编码器和推理模型\n",
    "encoder = make_encoder(params)\n",
    "inference = InferenceNCD(encoder, params)\n",
    "\n",
    "# 加载保存的模型\n",
    "inference.load(model_path, device)\n",
    "inference.eval()\n",
    "print(f\"推理模型加载完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 获取样本数据进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "收集了 100 个样本\n"
     ]
    }
   ],
   "source": [
    "# 创建缓冲区来收集样本\n",
    "buffer = ReplayBuffer(params)\n",
    "num_samples = 100\n",
    "current_samples = 0\n",
    "\n",
    "# 收集样本 - 使用单个环境\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "while current_samples < num_samples:\n",
    "    # 随机选择动作 - 单环境\n",
    "    action = np.random.randint(0, 5 * 10, size=1)  # 根据环境动作空间调整\n",
    "    next_obs, reward, done, info = env.step(action.item())\n",
    "    \n",
    "    # 添加到缓冲区 - 单环境\n",
    "    buffer.add(obs, action, reward, next_obs, done, info, True)\n",
    "    current_samples += 1\n",
    "    \n",
    "    # 如果回合结束，重置环境\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "    else:\n",
    "        obs = next_obs\n",
    "\n",
    "print(f\"收集了 {current_samples} 个样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'obj0': array([0]),\n",
       "  'obj1': array([1]),\n",
       "  'obj2': array([1]),\n",
       "  'obj3': array([0]),\n",
       "  'obj4': array([1]),\n",
       "  'obj5': array([0]),\n",
       "  'obj6': array([2]),\n",
       "  'obj7': array([2]),\n",
       "  'obj8': array([4]),\n",
       "  'obj9': array([0]),\n",
       "  'target_obj0': array([0]),\n",
       "  'target_obj1': array([1]),\n",
       "  'target_obj2': array([4]),\n",
       "  'target_obj3': array([0]),\n",
       "  'target_obj4': array([3]),\n",
       "  'target_obj5': array([4]),\n",
       "  'target_obj6': array([1]),\n",
       "  'target_obj7': array([2]),\n",
       "  'target_obj8': array([2]),\n",
       "  'target_obj9': array([0])},\n",
       " {'obj0': array([0.], dtype=float32),\n",
       "  'obj1': array([1.], dtype=float32),\n",
       "  'obj2': array([1.], dtype=float32),\n",
       "  'obj3': array([0.], dtype=float32),\n",
       "  'obj4': array([1.], dtype=float32),\n",
       "  'obj5': array([0.], dtype=float32),\n",
       "  'obj6': array([2.], dtype=float32),\n",
       "  'obj7': array([2.], dtype=float32),\n",
       "  'obj8': array([4.], dtype=float32),\n",
       "  'obj9': array([0.], dtype=float32),\n",
       "  'target_obj0': array([0.], dtype=float32),\n",
       "  'target_obj1': array([1.], dtype=float32),\n",
       "  'target_obj2': array([4.], dtype=float32),\n",
       "  'target_obj3': array([0.], dtype=float32),\n",
       "  'target_obj4': array([3.], dtype=float32),\n",
       "  'target_obj5': array([4.], dtype=float32),\n",
       "  'target_obj6': array([1.], dtype=float32),\n",
       "  'target_obj7': array([2.], dtype=float32),\n",
       "  'target_obj8': array([2.], dtype=float32),\n",
       "  'target_obj9': array([0.], dtype=float32)})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fcdl.utils.utils import preprocess_obs, postprocess_obs\n",
    "obs, postprocess_obs(preprocess_obs(obs, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从缓冲区获取样本\n",
    "batch_size = 13\n",
    "obs_batch, actions_batch, next_obses_batch, info_batch = buffer.sample_inference(batch_size, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [2.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_batch['obj0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 3, 10, 11])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_batch['lcms'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='cuda:0'),\n",
       " tensor([[7],\n",
       "         [4],\n",
       "         [5]], device='cuda:0'))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_batch['lcms'][0][0], actions_batch[0] // 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 验证模型预测的 Local Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用推理模型进行预测\n",
    "with torch.no_grad():\n",
    "    # 获取模型预测的local mask\n",
    "    pred_results = inference.eval_local_mask(obs_batch, actions_batch)\n",
    "    \n",
    "    # # 提取预测的local mask\n",
    "    # if hasattr(inference, 'pred_local_mask'):\n",
    "    #     pred_local_mask = inference.pred_local_mask\n",
    "    #     print(\"获取到模型预测的local mask\")\n",
    "    # else:\n",
    "    #     # 如果模型没有直接暴露pred_local_mask，尝试从pred_results获取\n",
    "    #     if 'local_mask' in pred_results:\n",
    "    #         pred_local_mask = pred_results['local_mask']\n",
    "    #         print(\"从pred_results获取了local mask\")\n",
    "    #     else:\n",
    "    #         print(\"警告：无法获取local mask预测结果\")\n",
    "    #         pred_local_mask = None\n",
    "    \n",
    "    # # 提取真实的local mask（如果有）\n",
    "    # if 'gt_local_mask' in info_batch:\n",
    "    #     gt_local_mask = info_batch['gt_local_mask']\n",
    "    #     print(\"获取到真实的local mask\")\n",
    "    # else:\n",
    "    #     print(\"警告：数据中没有真实的local mask\")\n",
    "    #     gt_local_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 13, 10, 11]), torch.Size([13, 3, 10, 11]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0].squeeze().shape, info_batch['lcms'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38.)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_results[0].squeeze().cpu()[0, 1] - info_batch['lcms'][0, 1].cpu()).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.500, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "          0.500],\n",
       "         [0.500, 0.500, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "          0.500],\n",
       "         [0.500, 0.500, 0.500, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "          0.500],\n",
       "         [0.500, 0.500, 0.500, 0.500, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "          0.500],\n",
       "         [0.500, 0.500, 0.500, 0.500, 0.500, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "          0.500],\n",
       "         [0.500, 0.500, 0.199, 0.500, 0.500, 0.500, 0.001, 0.001, 0.001, 0.001,\n",
       "          0.500],\n",
       "         [0.500, 0.500, 0.499, 0.498, 0.500, 0.500, 0.500, 0.001, 0.001, 0.001,\n",
       "          0.500],\n",
       "         [0.500, 0.500, 0.484, 0.445, 0.018, 0.001, 0.500, 0.500, 0.001, 0.001,\n",
       "          0.500],\n",
       "         [0.500, 0.500, 0.004, 0.500, 0.498, 0.043, 0.006, 0.500, 0.500, 0.001,\n",
       "          0.500],\n",
       "         [0.500, 0.498, 0.500, 0.499, 0.500, 0.500, 0.500, 0.016, 0.007, 0.500,\n",
       "          0.500]]),\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(pred_results[1].squeeze().cpu()[0, 1]), info_batch['lcms'][0, 1].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.],\n",
    "        [0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.]]).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0].squeeze().cpu()[0] - info_batch['lcms'][0, 0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析和可视化local mask（如果有）\n",
    "if pred_local_mask is not None:\n",
    "    print(\"预测的local mask形状:\", pred_local_mask.shape)\n",
    "    \n",
    "    # 显示第一个样本的预测mask\n",
    "    sample_idx = 0\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 获取矩阵的维度\n",
    "    mask_shape = pred_local_mask[sample_idx].shape\n",
    "    \n",
    "    # 创建热力图\n",
    "    sns.heatmap(pred_local_mask[sample_idx].cpu().numpy(), \n",
    "                annot=True, \n",
    "                fmt=\".2f\", \n",
    "                cmap=\"YlGnBu\",\n",
    "                xticklabels=[f\"Obj {i}\" for i in range(mask_shape[1])],\n",
    "                yticklabels=[f\"Obj {i}\" for i in range(mask_shape[0])])\n",
    "    \n",
    "    plt.title(\"预测的Local Mask (样本 #0)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 如果有真实的local mask，比较准确性\n",
    "    if gt_local_mask is not None:\n",
    "        # 计算预测与真实值的差异\n",
    "        accuracy = (pred_local_mask.round() == gt_local_mask).float().mean().item()\n",
    "        print(f\"Local mask准确率: {accuracy:.4f}\")\n",
    "        \n",
    "        # 显示真实的local mask\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(gt_local_mask[sample_idx].cpu().numpy(), \n",
    "                    annot=True, \n",
    "                    fmt=\".0f\", \n",
    "                    cmap=\"YlGnBu\",\n",
    "                    xticklabels=[f\"Obj {j}\" for j in range(mask_shape[1])],\n",
    "                    yticklabels=[f\"Obj {j}\" for j in range(mask_shape[0])])\n",
    "        \n",
    "        plt.title(\"真实的Local Mask (样本 #0)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"没有可用的local mask信息进行可视化\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 额外的分析：检查预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看所有的预测结果\n",
    "print(\"预测结果包含的键:\")\n",
    "for key in pred_results.keys():\n",
    "    print(f\"- {key}: {type(pred_results[key])}\")\n",
    "\n",
    "# 检查预测的状态转移\n",
    "if 'pred_next_state' in pred_results:\n",
    "    pred_next_state = pred_results['pred_next_state']\n",
    "    true_next_state = next_obses_batch\n",
    "    \n",
    "    # 计算预测误差\n",
    "    prediction_error = ((pred_next_state - true_next_state) ** 2).mean().item()\n",
    "    print(f\"\\n平均预测误差 (MSE): {prediction_error:.6f}\")\n",
    "    \n",
    "    # 显示第一个样本的预测与真实值比较\n",
    "    sample_idx = 0\n",
    "    \n",
    "    print(f\"\\n样本 #{sample_idx} 的预测值与真实值比较:\")\n",
    "    print(f\"预测下一状态:\\n{pred_next_state[sample_idx]}\")\n",
    "    print(f\"真实下一状态:\\n{true_next_state[sample_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 探索更多样本的local mask预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化多个样本的local mask预测\n",
    "if pred_local_mask is not None:\n",
    "    n_samples = min(4, batch_size)  # 显示最多4个样本\n",
    "    \n",
    "    fig, axes = plt.subplots(n_samples, 1, figsize=(10, n_samples * 6))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        ax = axes[i] if n_samples > 1 else axes\n",
    "        \n",
    "        # 创建热力图\n",
    "        sns.heatmap(pred_local_mask[i].cpu().numpy(), \n",
    "                    annot=True, \n",
    "                    fmt=\".2f\", \n",
    "                    cmap=\"YlGnBu\",\n",
    "                    ax=ax,\n",
    "                    xticklabels=[f\"Obj {j}\" for j in range(mask_shape[1])],\n",
    "                    yticklabels=[f\"Obj {j}\" for j in range(mask_shape[0])])\n",
    "        \n",
    "        ax.set_title(f\"预测的Local Mask (样本 #{i})\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 保存分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建结果目录\n",
    "results_dir = \"local_mask_analysis_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 如果有预测的local mask，将其保存为CSV文件\n",
    "if pred_local_mask is not None:\n",
    "    for i in range(min(10, batch_size)):  # 保存前10个样本\n",
    "        # 转换为DataFrame\n",
    "        df = pd.DataFrame(pred_local_mask[i].cpu().numpy())\n",
    "        df.columns = [f\"Obj {j}\" for j in range(df.shape[1])]\n",
    "        df.index = [f\"Obj {j}\" for j in range(df.shape[0])]\n",
    "        \n",
    "        # 保存为CSV\n",
    "        df.to_csv(os.path.join(results_dir, f\"local_mask_sample_{i}.csv\"))\n",
    "    \n",
    "    print(f\"已保存local mask预测结果到 {results_dir} 目录\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 总结和解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析结论\n",
    "\n",
    "我们通过以下步骤验证了推理模型预测的local mask:\n",
    "\n",
    "1. 加载了保存的模型权重和参数\n",
    "2. 重建了与训练时相同的环境\n",
    "3. 收集了新的样本数据\n",
    "4. 使用推理模型生成了local mask预测\n",
    "5. 可视化并分析了预测结果\n",
    "\n",
    "**Local Mask 解释**:\n",
    "- Local mask矩阵中的每个元素表示行对象对列对象的影响程度\n",
    "- 值接近1表示存在强影响关系，值接近0表示几乎没有影响\n",
    "- 通过观察local mask，我们可以了解对象之间的因果关系结构\n",
    "\n",
    "这些分析结果可以帮助我们理解模型是如何捕获环境中的因果关系，以及这些关系的准确性程度。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
